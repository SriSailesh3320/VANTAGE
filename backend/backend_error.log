Traceback (most recent call last):
  File "C:\Projects\Cyborg.AI\SmartStockAgent\backend\main.py", line 32, in chat
    result = agent_app.invoke(inputs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langgraph\pregel\main.py", line 3068, in invoke
    for chunk in self.stream(
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langgraph\pregel\main.py", line 2643, in stream
    for _ in runner.tick(
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langgraph\pregel\_runner.py", line 167, in tick
    run_with_retry(
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langgraph\pregel\_retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langgraph\_internal\_runnable.py", line 656, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langgraph\_internal\_runnable.py", line 400, in invoke
    ret = self.func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Projects\Cyborg.AI\SmartStockAgent\backend\agent.py", line 66, in agent
    response = llm_with_tools.invoke(messages)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain_core\runnables\base.py", line 5534, in invoke
    return self.bound.invoke(
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain_core\language_models\chat_models.py", line 398, in invoke
    self.generate_prompt(
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1117, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain_core\language_models\chat_models.py", line 927, in generate
    self._generate_with_cache(
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1221, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain_openai\chat_models\base.py", line 1356, in _generate
    raise e
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\langchain_openai\chat_models\base.py", line 1351, in _generate
    raw_response = self.client.with_raw_response.create(**payload)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_legacy_response.py", line 364, in wrapped
    return cast(LegacyAPIResponse[R], func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_utils\_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\resources\chat\completions\completions.py", line 1189, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\srisa\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-min. ', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '16', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1764694320000'}, 'provider_name': None}}, 'user_id': 'user_2tjagYAI79hiJq5I0LAnmOwoMlz'}
During task with name 'agent' and id '2208f084-d8be-c1a1-6b15-a22f11d1f840'
